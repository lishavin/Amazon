{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "9Fk3GfVH3a3G",
        "5f8dP3615L2p",
        "MJxACWVIQEF8",
        "pUC59DTrRhYo",
        "W2y-gVxQfCjB",
        "Oz5UM2DLam6X",
        "ixnYmNLXO_LX",
        "uk-Ujcg7QKXr",
        "w7QloeVyS91Z",
        "3263Yn7NfsuV",
        "AlPrlqckhIcY",
        "Ge7uZX1Pj6I4",
        "-XFEIGAOknUo",
        "fXhv4fCbk69M",
        "vbdAaR3JojvY"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lishavin/Amazon/blob/main/Glove%2BSVM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0. Required Packages\n",
        "\n",
        "- 파일 > Drive에 사본 저장\n",
        "- 아래 패키지 설치 후 session restart 필요 (런타임 > 세션다시시작)\n",
        "- drive mount (pretrained weight)"
      ],
      "metadata": {
        "id": "sENqptvHUisT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets\n",
        "!pip install numpy==1.26\n",
        "!pip install scipy==1.13.1\n",
        "!pip install gensim\n",
        "!pip install fsspec==2023.4.0 #\"**\" 경로 패턴 호환되는 fsspec 옛날버전으로 다운그레이드\n",
        "\n",
        "!pip install nltk"
      ],
      "metadata": {
        "id": "G9aLq4ZATesT",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "_ilO50MAuNUv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8SSipMlOTUml"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from tqdm import tqdm\n",
        "import nltk #토큰화, 불용어 제거, 표제어 추출 등을 위한 자원 다운로드\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Load Data"
      ],
      "metadata": {
        "id": "joSdnEARUlDs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "df = load_dataset(\"fancyzhx/amazon_polarity\")\n",
        "\n",
        "# train과 test를 각각 pandas DataFrame으로 변환\n",
        "train_df = df[\"train\"].select(range(10000)).to_pandas()\n",
        "test_df = df[\"test\"].select(range(5000)).to_pandas()"
      ],
      "metadata": {
        "id": "sLPn7NAZTb6W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(train_df)\n",
        "type(test_df)"
      ],
      "metadata": {
        "id": "52lgghqYIlo4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. EDA\n"
      ],
      "metadata": {
        "id": "xSo0G0RAUmbv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 1 : positive\n",
        "- 0 : negative"
      ],
      "metadata": {
        "id": "9Wx9q1DJSxBm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head()"
      ],
      "metadata": {
        "id": "DGqxjaUDWeAG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data type 확인\n",
        "print(\"Train Dataset DataType\")\n",
        "print(train_df.dtypes)\n",
        "\n",
        "print(\"\\nTest Dataset DataType\")\n",
        "print(test_df.dtypes)"
      ],
      "metadata": {
        "id": "tWzrTcd7WtFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.isnull()"
      ],
      "metadata": {
        "id": "OqNMb3m0JFUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#결측치 확인\n",
        "print(\"Train Dataset 결측치\")\n",
        "print(train_df.isnull().sum())\n",
        "\n",
        "print(\"\\nTest Dataset 결측치\")\n",
        "print(test_df.isnull().sum())"
      ],
      "metadata": {
        "id": "1sjzijn4WyBD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#label 비율 확인\n",
        "import seaborn as sns\n",
        "sns.countplot(x='label', data= train_df)\n",
        "print(train_df.label.value_counts())"
      ],
      "metadata": {
        "id": "nIOr90GaXJ6o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#label 비율 확인\n",
        "sns.countplot(x='label', data= test_df)\n",
        "print(test_df.label.value_counts())"
      ],
      "metadata": {
        "id": "UL-Jz5lUXZZ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df"
      ],
      "metadata": {
        "id": "2B_vvPTeXzaH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Text Cleaning"
      ],
      "metadata": {
        "id": "9Fk3GfVH3a3G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        ">1. 정규표현식\n",
        "  - HTML 태그 제거\n",
        "  - 특수문자 제거\n",
        "2. 소문자 변환\n",
        "3. Stopwords 제거\n",
        "4. Stemming (어간 추출) /Lemmatization (표제어 추출)\n",
        "\n"
      ],
      "metadata": {
        "id": "hSV-0HR3Nbe2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Amazon 데이터에 적용"
      ],
      "metadata": {
        "id": "TmqEjPLQMrub"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# title과 content 열 합치기\n",
        "train_df[\"review\"] = train_df[\"title\"] + \" \" + train_df[\"content\"]\n",
        "test_df[\"review\"] = test_df[\"title\"] + \" \" + test_df[\"content\"]"
      ],
      "metadata": {
        "id": "E5uczMGdOhco"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re #정규표현식 regular expression: HTML 태그나 특수문자 제거시 사용\n",
        "import nltk\n",
        "from nltk.corpus import stopwords #nltk에서 제공하는 불용어(stopwords) 리스트를 불러오기 위한 것\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer #어간 추출, 표제어 추출\n",
        "\n",
        "# 처음 한 번은 다운로드 필요\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "def preprocess_review(review):\n",
        "    # HTML 태그 제거\n",
        "    review = re.sub('<[^>]*>', '', review)\n",
        "    # 특수 문자 제거 (!는 남기기)\n",
        "    review = re.sub('[^a-zA-Z0-9 ?]', '', review)\n",
        "    # 소문자 변환\n",
        "    review = review.lower()\n",
        "    # 토큰화\n",
        "    tokens = word_tokenize(review)\n",
        "    # 불용어 제거\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "    # 표제어 추출\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "\n",
        "    return \" \".join(tokens)"
      ],
      "metadata": {
        "id": "xZmPGCKm31ib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 전처리 적용\n",
        "train_df['processed_review'] = train_df['review'].apply(preprocess_review)\n",
        "test_df['processed_review'] = test_df['review'].apply(preprocess_review)"
      ],
      "metadata": {
        "id": "Zx4GvXa-48xU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head()"
      ],
      "metadata": {
        "id": "f-MxJ-AparoZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Train-Valid Split"
      ],
      "metadata": {
        "id": "W2y-gVxQfCjB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 80% train, 20% validation\n",
        "data_train, data_valid = train_test_split(\n",
        "    train_df,                  # 원래 train 데이터셋\n",
        "    test_size=0.2,             # 20%는 validation으로\n",
        "    stratify=train_df['label'], # label 비율 유지 (긍/부정 균형)\n",
        "    random_state=42           # 재현성 (같은 split 결과)\n",
        ")\n",
        "\n",
        "data_test = test_df           # 테스트는 이미 별도로 있음"
      ],
      "metadata": {
        "id": "zd5S9b8pfKkP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(data_train)"
      ],
      "metadata": {
        "id": "Mku9ygoRMeXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(data_valid)"
      ],
      "metadata": {
        "id": "rLmnGrAyMf5X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Vectorization + Classifier"
      ],
      "metadata": {
        "id": "Oz5UM2DLam6X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Glove\n"
      ],
      "metadata": {
        "id": "w7QloeVyS91Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GloVe 벡터 로딩\n",
        "def load_glove_model(glove_file_path):\n",
        "    print(\"Loading GloVe model...\")\n",
        "    glove_model = {}\n",
        "    with open(glove_file_path, encoding=\"utf-8\") as f:\n",
        "        for line in tqdm(f):\n",
        "            parts = line.strip().split()\n",
        "            word = parts[0]\n",
        "            vector = np.array(parts[1:], dtype=np.float32)\n",
        "            glove_model[word] = vector\n",
        "    print(f\"{len(glove_model)} words loaded!\")\n",
        "    return glove_model\n",
        "\n",
        "# 문장 → 평균 벡터 변환\n",
        "def sentence_to_vector(sentence, glove_model, vector_dim=300):\n",
        "    tokens = sentence.split()\n",
        "    vecs = [glove_model[word] for word in tokens if word in glove_model]\n",
        "    if not vecs:\n",
        "        return np.zeros(vector_dim)\n",
        "    return np.mean(vecs, axis=0)"
      ],
      "metadata": {
        "id": "KOw4ABHdrVN8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GloVe 모델 로드 (Stanford에서 사전학습한 모델)\n",
        "glove_path = \"/content/drive/MyDrive/weights/glove.6B.300d.txt\"  # 위치 맞게 지정\n",
        "glove_model = load_glove_model(glove_path)"
      ],
      "metadata": {
        "id": "QAm_W1mGrWRI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "glove_model['king']"
      ],
      "metadata": {
        "id": "SOvw88CorYEg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 각 리뷰를 벡터로 변환\n",
        "tqdm.pandas()\n",
        "X_train_vec = data_train['processed_review'].progress_apply(lambda x: sentence_to_vector(x, glove_model, 300))\n",
        "X_valid_vec = data_valid['processed_review'].progress_apply(lambda x: sentence_to_vector(x, glove_model, 300))\n",
        "X_test_vec = data_test['processed_review'].progress_apply(lambda x: sentence_to_vector(x, glove_model, 300))\n",
        "\n",
        "# numpy array로 변환\n",
        "X_train_vec = np.stack(X_train_vec.values)\n",
        "X_valid_vec = np.stack(X_valid_vec.values)\n",
        "X_test_vec = np.stack(X_test_vec.values)\n",
        "\n",
        "y_train = data_train['label'].values\n",
        "y_valid = data_valid['label'].values\n",
        "y_test = data_test['label'].values"
      ],
      "metadata": {
        "id": "gQ_2Gd2drbFd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train_vec.shape)\n",
        "print(X_train_vec[0][:50])"
      ],
      "metadata": {
        "id": "swm67jHvrc2v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Linear SVM"
      ],
      "metadata": {
        "id": "4OAnltifrfVU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# SVM 모델 정의\n",
        "svm_clf = SVC(kernel='linear')\n",
        "\n",
        "# 모델 학습\n",
        "svm_clf.fit(X_train_vec, y_train)\n",
        "\n",
        "# 예측\n",
        "svm_valid_preds = svm_clf.predict(X_valid_vec)\n",
        "svm_test_preds = svm_clf.predict(X_test_vec)\n",
        "\n",
        "# 성능 평가\n",
        "print(\"Validation Accuracy:\", accuracy_score(y_valid, svm_valid_preds))\n",
        "print(\"Test Accuracy:\", accuracy_score(y_test, svm_test_preds))\n",
        "print(\"\\n[Classification Report on Test Set]\\n\", classification_report(y_test, svm_test_preds))"
      ],
      "metadata": {
        "id": "P777x7ehrtCH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cross Validation 1\n",
        "K-fold 선택: 튜닝 전 baseline 성능을 확인\n"
      ],
      "metadata": {
        "id": "N67aE9ZIopxi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.svm import SVC\n",
        "import numpy as np\n",
        "\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "fold_accuracies = []\n",
        "\n",
        "for fold, (train_index, valid_index) in enumerate(kf.split(X_train_vec)):\n",
        "    X_tr, X_val = X_train_vec[train_index], X_train_vec[valid_index]\n",
        "    y_tr, y_val = y_train[train_index], y_train[valid_index]\n",
        "\n",
        "    svm_clf = SVC(kernel='linear')\n",
        "    svm_clf.fit(X_tr, y_tr)\n",
        "\n",
        "    val_preds = svm_clf.predict(X_val)\n",
        "    acc = accuracy_score(y_val, val_preds)\n",
        "    fold_accuracies.append(acc)\n",
        "\n",
        "    print(f\"[Fold {fold+1}] Validation Accuracy: {acc:.4f}\")\n",
        "\n",
        "print(f\"\\n📊 Average Validation Accuracy (Baseline - KFold 5): {np.mean(fold_accuracies):.4f}\")"
      ],
      "metadata": {
        "id": "DvCGpgTN5lGR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameter Tuning\n",
        "\n",
        "이미 모델 성능이 좋아서 정밀한 전수조사(Grid)보다는 \t빠르게 근사 최적값을 찾는 게 더 중요해서 Random Search로 최적 C, penalty 값 찾기\n"
      ],
      "metadata": {
        "id": "LtES2bAOn33U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import uniform\n",
        "\n",
        "# 탐색할 하이퍼파라미터 범위 정의\n",
        "param_dist = {\n",
        "    'C': uniform(loc=0.01, scale=10),  # 정규화 파라미터\n",
        "    'kernel': ['linear'],              # 선형 SVM 고정\n",
        "}\n",
        "\n",
        "# RandomizedSearch 정의\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=SVC(),\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=20,\n",
        "    scoring='accuracy',\n",
        "    cv=5,\n",
        "    verbose=1,\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# 학습\n",
        "random_search.fit(X_train_vec, y_train)\n",
        "\n",
        "# 최적 결과 출력\n",
        "print(\"Best Parameters:\", random_search.best_params_)\n",
        "print(\"Best CV Accuracy:\", random_search.best_score_)\n",
        "\n",
        "# 최적 모델 추출\n",
        "best_svm = random_search.best_estimator_"
      ],
      "metadata": {
        "id": "aqrBJk2coKjI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cross Validation 2\n",
        "튜닝 후 최종 모델을 재검증: RandomizedSearch 결과가 얼마나 개선됐는지 비교"
      ],
      "metadata": {
        "id": "qoOBEnIhtYnE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "tuned_fold_accuracies = []\n",
        "\n",
        "for fold, (train_index, valid_index) in enumerate(kf.split(X_train_vec)):\n",
        "    X_tr, X_val = X_train_vec[train_index], X_train_vec[valid_index]\n",
        "    y_tr, y_val = y_train[train_index], y_train[valid_index]\n",
        "\n",
        "    best_svm.fit(X_tr, y_tr)\n",
        "    val_preds = best_svm.predict(X_val)\n",
        "    acc = accuracy_score(y_val, val_preds)\n",
        "    tuned_fold_accuracies.append(acc)\n",
        "\n",
        "    print(f\"[Fold {fold+1}] Validation Accuracy (Tuned): {acc:.4f}\")\n",
        "\n",
        "print(f\"\\n✅ Average Validation Accuracy (Tuned - KFold 5): {np.mean(tuned_fold_accuracies):.4f}\")"
      ],
      "metadata": {
        "id": "AWhbRfeyu0Nf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}