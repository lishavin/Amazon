{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "9Fk3GfVH3a3G",
        "5f8dP3615L2p",
        "MJxACWVIQEF8",
        "pUC59DTrRhYo",
        "W2y-gVxQfCjB",
        "Oz5UM2DLam6X",
        "ixnYmNLXO_LX",
        "uk-Ujcg7QKXr",
        "w7QloeVyS91Z",
        "3263Yn7NfsuV",
        "AlPrlqckhIcY",
        "Ge7uZX1Pj6I4",
        "-XFEIGAOknUo",
        "fXhv4fCbk69M",
        "vbdAaR3JojvY"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lishavin/Amazon/blob/main/TF-IDF%2BLogistic_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0. Required Packages\n",
        "\n",
        "- 파일 > Drive에 사본 저장\n",
        "- 아래 패키지 설치 후 session restart 필요 (런타임 > 세션다시시작)\n",
        "- drive mount (pretrained weight)"
      ],
      "metadata": {
        "id": "sENqptvHUisT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets\n",
        "!pip install numpy==1.26\n",
        "!pip install scipy==1.13.1\n",
        "!pip install gensim\n",
        "!pip install fsspec==2023.4.0 #\"**\" 경로 패턴 호환되는 fsspec 옛날버전으로 다운그레이드\n",
        "\n",
        "!pip install nltk"
      ],
      "metadata": {
        "id": "G9aLq4ZATesT",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "_ilO50MAuNUv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8SSipMlOTUml"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from tqdm import tqdm\n",
        "import nltk #토큰화, 불용어 제거, 표제어 추출 등을 위한 자원 다운로드\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Load Data"
      ],
      "metadata": {
        "id": "joSdnEARUlDs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "df = load_dataset(\"fancyzhx/amazon_polarity\")\n",
        "\n",
        "# train과 test를 각각 pandas DataFrame으로 변환\n",
        "train_df = df[\"train\"].select(range(10000)).to_pandas()\n",
        "test_df = df[\"test\"].select(range(5000)).to_pandas()"
      ],
      "metadata": {
        "id": "sLPn7NAZTb6W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(train_df)\n",
        "type(test_df)"
      ],
      "metadata": {
        "id": "52lgghqYIlo4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. EDA\n"
      ],
      "metadata": {
        "id": "xSo0G0RAUmbv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 1 : positive\n",
        "- 0 : negative"
      ],
      "metadata": {
        "id": "9Wx9q1DJSxBm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head()"
      ],
      "metadata": {
        "id": "DGqxjaUDWeAG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data type 확인\n",
        "print(\"Train Dataset DataType\")\n",
        "print(train_df.dtypes)\n",
        "\n",
        "print(\"\\nTest Dataset DataType\")\n",
        "print(test_df.dtypes)"
      ],
      "metadata": {
        "id": "tWzrTcd7WtFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.isnull()"
      ],
      "metadata": {
        "id": "OqNMb3m0JFUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#결측치 확인\n",
        "print(\"Train Dataset 결측치\")\n",
        "print(train_df.isnull().sum())\n",
        "\n",
        "print(\"\\nTest Dataset 결측치\")\n",
        "print(test_df.isnull().sum())"
      ],
      "metadata": {
        "id": "1sjzijn4WyBD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#label 비율 확인\n",
        "import seaborn as sns\n",
        "sns.countplot(x='label', data= train_df)\n",
        "print(train_df.label.value_counts())"
      ],
      "metadata": {
        "id": "nIOr90GaXJ6o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#label 비율 확인\n",
        "sns.countplot(x='label', data= test_df)\n",
        "print(test_df.label.value_counts())"
      ],
      "metadata": {
        "id": "UL-Jz5lUXZZ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df"
      ],
      "metadata": {
        "id": "2B_vvPTeXzaH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Text Cleaning"
      ],
      "metadata": {
        "id": "9Fk3GfVH3a3G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        ">1. 정규표현식\n",
        "  - HTML 태그 제거\n",
        "  - 특수문자 제거\n",
        "2. 소문자 변환\n",
        "3. Stopwords 제거\n",
        "4. Stemming (어간 추출) /Lemmatization (표제어 추출)\n",
        "\n"
      ],
      "metadata": {
        "id": "hSV-0HR3Nbe2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Amazon 데이터에 적용"
      ],
      "metadata": {
        "id": "TmqEjPLQMrub"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# title과 content 열 합치기\n",
        "train_df[\"review\"] = train_df[\"title\"] + \" \" + train_df[\"content\"]\n",
        "test_df[\"review\"] = test_df[\"title\"] + \" \" + test_df[\"content\"]"
      ],
      "metadata": {
        "id": "E5uczMGdOhco"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re #정규표현식 regular expression: HTML 태그나 특수문자 제거시 사용\n",
        "import nltk\n",
        "from nltk.corpus import stopwords #nltk에서 제공하는 불용어(stopwords) 리스트를 불러오기 위한 것\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer #어간 추출, 표제어 추출\n",
        "\n",
        "# 처음 한 번은 다운로드 필요\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "def preprocess_review(review):\n",
        "    # HTML 태그 제거\n",
        "    review = re.sub('<[^>]*>', '', review)\n",
        "    # 특수 문자 제거 (!는 남기기)\n",
        "    review = re.sub('[^a-zA-Z0-9 ?]', '', review)\n",
        "    # 소문자 변환\n",
        "    review = review.lower()\n",
        "    # 토큰화\n",
        "    tokens = word_tokenize(review)\n",
        "    # 불용어 제거\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "    # 표제어 추출\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "\n",
        "    return \" \".join(tokens)"
      ],
      "metadata": {
        "id": "xZmPGCKm31ib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 전처리 적용\n",
        "train_df['processed_review'] = train_df['review'].apply(preprocess_review)\n",
        "test_df['processed_review'] = test_df['review'].apply(preprocess_review)"
      ],
      "metadata": {
        "id": "Zx4GvXa-48xU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head()"
      ],
      "metadata": {
        "id": "f-MxJ-AparoZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Train-Valid Split"
      ],
      "metadata": {
        "id": "W2y-gVxQfCjB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 80% train, 20% validation\n",
        "data_train, data_valid = train_test_split(\n",
        "    train_df,                  # 원래 train 데이터셋\n",
        "    test_size=0.2,             # 20%는 validation으로\n",
        "    stratify=train_df['label'], # label 비율 유지 (긍/부정 균형)\n",
        "    random_state=42           # 재현성 (같은 split 결과)\n",
        ")\n",
        "\n",
        "data_test = test_df           # 테스트는 이미 별도로 있음"
      ],
      "metadata": {
        "id": "zd5S9b8pfKkP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(data_train)"
      ],
      "metadata": {
        "id": "Mku9ygoRMeXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(data_valid)"
      ],
      "metadata": {
        "id": "rLmnGrAyMf5X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Vectorization + Classifier"
      ],
      "metadata": {
        "id": "Oz5UM2DLam6X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **TF-IDF Vectorizer**"
      ],
      "metadata": {
        "id": "uk-Ujcg7QKXr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# TF-IDF 벡터화 (최대 10000개의 단어 사용)\n",
        "vectorizer = TfidfVectorizer(max_features=10000)\n",
        "\n",
        "# 학습 데이터로 학습 + 변환\n",
        "X_train = vectorizer.fit_transform(data_train['processed_review'])\n",
        "X_valid = vectorizer.transform(data_valid['processed_review'])\n",
        "X_test = vectorizer.transform(data_test['processed_review'])\n",
        "\n",
        "# 감성 분류의 정답(label)값을 따로 분리해서 저장\n",
        "y_train = data_train[\"label\"]\n",
        "y_valid = data_valid[\"label\"]\n",
        "y_test = data_test[\"label\"]"
      ],
      "metadata": {
        "id": "TVj_smEPQIPX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#벡터 확인\n",
        "print(X_train[0].toarray()[0][170:250])\n",
        "print(len(X_train[0].toarray()[0])) # 총 벡터 길이: 10,000"
      ],
      "metadata": {
        "id": "eEX0MfGPSV-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 0이 아닌 항목 수 확인: 14개로 잘 나옴\n",
        "nonzero_count = (X_train[0].toarray() != 0).sum()\n",
        "print(\"Non-zero TF-IDF features:\", nonzero_count)"
      ],
      "metadata": {
        "id": "HouypEjxMeO_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Logistic Regression**"
      ],
      "metadata": {
        "id": "vbdAaR3JojvY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 결과에 대한 확률값 출력 가능\n",
        "- 선형 결정 경계만 학습 가능 (복잡한 패턴은 한계가 있음) <br>\n",
        "[참고docs](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)"
      ],
      "metadata": {
        "id": "m9URfTv2opYh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "#model load\n",
        "log_clf = LogisticRegression(max_iter=1000)\n",
        "\n",
        "#train\n",
        "log_clf.fit(X_train, y_train)\n",
        "\n",
        "#prediction\n",
        "lr_valid_preds = log_clf.predict(X_valid)\n",
        "lr_test_preds = log_clf.predict(X_test)\n",
        "\n",
        "print(\"Validation Accuracy:\", accuracy_score(y_valid, lr_valid_preds))\n",
        "print(\"Test Accuracy:\", accuracy_score(y_test, lr_test_preds))\n",
        "print(\"\\n[Classification Report on Test Set]\\n\", classification_report(y_test, lr_test_preds))"
      ],
      "metadata": {
        "id": "eowMa0OapJWz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cross Validation 1\n",
        "K-fold 선택: 튜닝 전 baseline 성능을 확인\n"
      ],
      "metadata": {
        "id": "N67aE9ZIopxi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "fold_accuracies = []  # 정확도 저장용 리스트 선언\n",
        "y_train = y_train.values  # 또는 y_train = np.array(y_train)\n",
        "\n",
        "# 그 다음 K-Fold 코드 정상 작동\n",
        "for fold, (train_index, valid_index) in enumerate(kf.split(X_train)):\n",
        "    X_tr, X_val = X_train[train_index], X_train[valid_index]\n",
        "    y_tr, y_val = y_train[train_index], y_train[valid_index]\n",
        "\n",
        "    log_clf.fit(X_tr, y_tr)\n",
        "    val_preds = log_clf.predict(X_val)\n",
        "    acc = accuracy_score(y_val, val_preds)\n",
        "    fold_accuracies.append(acc)\n",
        "\n",
        "    print(f\"[Pre-Tuning Fold {fold+1}] Validation Accuracy: {acc:.4f}\")\n",
        "\n",
        "print(f\"\\n🔎 Average Validation Accuracy (Pre-Tuning 5-Fold): {np.mean(fold_accuracies):.4f}\")"
      ],
      "metadata": {
        "id": "DvCGpgTN5lGR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameter Tuning\n",
        "\n",
        "이미 모델 성능이 좋아서 정밀한 전수조사(Grid)보다는 \t빠르게 근사 최적값을 찾는 게 더 중요해서 Random Search로 최적 C, penalty 값 찾기\n"
      ],
      "metadata": {
        "id": "LtES2bAOn33U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#RandomizedSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from scipy.stats import uniform\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# 하이퍼파라미터 범위 설정\n",
        "param_dist = {\n",
        "    'C': uniform(loc=0.001, scale=10),  # 0.001 ~ 10 사이 연속값\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'solver': ['liblinear']  # l1을 지원하는 solver\n",
        "}\n",
        "\n",
        "# RandomizedSearchCV 정의\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=LogisticRegression(max_iter=1000),\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=20,                  # 20개의 조합을 무작위로 시도\n",
        "    scoring='accuracy',\n",
        "    cv=5,\n",
        "    random_state=42,\n",
        "    verbose=1,\n",
        "    n_jobs=-1                  # 가능한 모든 CPU 사용\n",
        ")\n",
        "\n",
        "# 학습\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# 최적 하이퍼파라미터 출력\n",
        "print(\"Best Parameters:\", random_search.best_params_)\n",
        "print(\"Best CV Accuracy:\", random_search.best_score_)"
      ],
      "metadata": {
        "id": "aqrBJk2coKjI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cross Validation 2\n",
        "튜닝 후 최종 모델을 재검증: RandomizedSearch 결과가 얼마나 개선됐는지 비교"
      ],
      "metadata": {
        "id": "qoOBEnIhtYnE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# RandomizedSearchCV 이후 최적 모델 가져오기\n",
        "best_model = random_search.best_estimator_\n",
        "\n",
        "# 튜닝 후 K-Fold 재설정\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "tuned_fold_accuracies = []\n",
        "\n",
        "for fold, (train_index, valid_index) in enumerate(kf.split(X_train)):\n",
        "    X_tr, X_val = X_train[train_index], X_train[valid_index]\n",
        "    y_tr, y_val = y_train[train_index], y_train[valid_index]\n",
        "\n",
        "    best_model.fit(X_tr, y_tr)\n",
        "    val_preds = best_model.predict(X_val)\n",
        "    acc = accuracy_score(y_val, val_preds)\n",
        "    tuned_fold_accuracies.append(acc)\n",
        "\n",
        "    print(f\"[Post-Tuning Fold {fold+1}] Validation Accuracy: {acc:.4f}\")\n",
        "\n",
        "print(f\"\\n✅ Average Validation Accuracy (Post-Tuning 5-Fold): {np.mean(tuned_fold_accuracies):.4f}\")"
      ],
      "metadata": {
        "id": "m-WexM-dteQx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 추가 분석\n"
      ],
      "metadata": {
        "id": "-N2QwHqHgt2g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 감성에 영향을 주는 주요 단어 분석 (model.coef_)"
      ],
      "metadata": {
        "id": "BetJKF4JhcUC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# 가장 영향력 있는 단어\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "coefficients = log_clf.coef_[0]\n",
        "\n",
        "# 긍정 영향력이 큰 단어 상위 10개\n",
        "top_pos_indices = np.argsort(coefficients)[-10:]\n",
        "print(\"Top positive words:\")\n",
        "for idx in reversed(top_pos_indices):\n",
        "    print(f\"{feature_names[idx]}: {coefficients[idx]:.4f}\")\n",
        "\n",
        "# 부정 영향력이 큰 단어 하위 10개\n",
        "top_neg_indices = np.argsort(coefficients)[:10]\n",
        "print(\"\\nTop negative words:\")\n",
        "for idx in top_neg_indices:\n",
        "    print(f\"{feature_names[idx]}: {coefficients[idx]:.4f}\")"
      ],
      "metadata": {
        "id": "yuH8Bh9bg0sM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 긍정 단어\n",
        "top_pos_words = {feature_names[idx]: coefficients[idx] for idx in top_pos_indices}\n",
        "wordcloud_pos = WordCloud(width=600, height=400, background_color='white', colormap='Blues').generate_from_frequencies(top_pos_words)\n",
        "\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.imshow(wordcloud_pos, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.title(\"Top Positive Words\")\n",
        "plt.show()\n",
        "\n",
        "# 부정 단어\n",
        "top_neg_words = {feature_names[idx]: abs(coefficients[idx]) for idx in top_neg_indices}\n",
        "wordcloud_neg = WordCloud(width=600, height=400, background_color='white', colormap='Reds').generate_from_frequencies(top_neg_words)\n",
        "\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.imshow(wordcloud_neg, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.title(\"Top Negative Words\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5nXZ7unE1j6_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 제품 카테고리별 감성 분포 분석"
      ],
      "metadata": {
        "id": "BZTrqK4VjTA1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 제품군 분류 함수 정의\n",
        "def classify_product(text):\n",
        "    text = text.lower()\n",
        "    if \"book\" in text:\n",
        "        return \"Book\"\n",
        "    elif \"camera\" in text or \"lens\" in text:\n",
        "        return \"Electronics\"\n",
        "    elif \"shoe\" in text or \"shirt\" in text:\n",
        "        return \"Clothing\"\n",
        "    else:\n",
        "        return \"Other\"\n",
        "\n",
        "train_df[\"product_group\"] = train_df[\"review\"].apply(classify_product)"
      ],
      "metadata": {
        "id": "JkTpkAVEjYhD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 제품군별 감성 분포 시각화\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sns.countplot(data=train_df, x=\"product_group\", hue=\"label\")\n",
        "plt.title(\"Sentiment Distribution by Product Group\")\n",
        "plt.xlabel(\"Product Category\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CH9gab1UjdTw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 리뷰 길이 vs 감성 관계"
      ],
      "metadata": {
        "id": "uZWuBZsWjhHG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 리뷰 길이 추가\n",
        "train_df[\"review_length\"] = train_df[\"review\"].apply(lambda x: len(x.split()))\n",
        "\n",
        "# 시각화\n",
        "sns.boxplot(data=train_df, x=\"label\", y=\"review_length\")\n",
        "plt.title(\"Review Length by Sentiment\")\n",
        "plt.xlabel(\"Sentiment (0=Neg, 1=Pos)\")\n",
        "plt.ylabel(\"Number of Words\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rmkVTEd4jlLy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 분류기 성능 비교(SVM, Naive Bayes, Decision Tree)"
      ],
      "metadata": {
        "id": "N37jnHNajoR7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "models = {\n",
        "    \"SVM\": LinearSVC(),\n",
        "    \"Naive Bayes\": MultinomialNB(),\n",
        "    \"Decision Tree\": DecisionTreeClassifier()\n",
        "}\n",
        "\n",
        "for name, clf in models.items():\n",
        "    clf.fit(X_train, y_train)\n",
        "    preds = clf.predict(X_valid)\n",
        "    acc = accuracy_score(y_valid, preds)\n",
        "    print(f\"{name} Accuracy: {acc:.4f}\")"
      ],
      "metadata": {
        "id": "fLEPDfGdjyoj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}